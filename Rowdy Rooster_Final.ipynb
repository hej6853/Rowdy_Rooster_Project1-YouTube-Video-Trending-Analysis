{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import itertools\n",
    "import nltk\n",
    "import chardet\n",
    "import string\n",
    "import pprint\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "import scipy.stats as st\n",
    "from scipy.stats import linregress\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from collections import Counter\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file\n",
    "US = pd.read_csv('Dataset/US_youtube_trending_data.csv') \n",
    "GB = pd.read_csv('Dataset/GB_youtube_trending_data.csv')\n",
    "CA = pd.read_csv('Dataset/CA_youtube_trending_data.csv')\n",
    "\n",
    "US['country'] = 'US'\n",
    "GB['country'] = 'GB'\n",
    "CA['country'] = 'CA'\n",
    "frames = [US, GB, CA]\n",
    "\n",
    "#merge\n",
    "df = pd.concat(frames).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_id</th>\n",
       "      <th>title</th>\n",
       "      <th>publishedAt</th>\n",
       "      <th>channelTitle</th>\n",
       "      <th>categoryId</th>\n",
       "      <th>trending_date</th>\n",
       "      <th>tags</th>\n",
       "      <th>view_count</th>\n",
       "      <th>likes</th>\n",
       "      <th>dislikes</th>\n",
       "      <th>comment_count</th>\n",
       "      <th>description</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3C66w5Z0ixs</td>\n",
       "      <td>I ASKED HER TO BE MY GIRLFRIEND...</td>\n",
       "      <td>2020-08-11T19:20:14Z</td>\n",
       "      <td>Brawadis</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>brawadis|prank|basketball|skits|ghost|funny vi...</td>\n",
       "      <td>1514614</td>\n",
       "      <td>156908</td>\n",
       "      <td>5855</td>\n",
       "      <td>35313</td>\n",
       "      <td>SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M9Pmf9AB4Mo</td>\n",
       "      <td>Apex Legends | Stories from the Outlands – “Th...</td>\n",
       "      <td>2020-08-11T17:00:10Z</td>\n",
       "      <td>Apex Legends</td>\n",
       "      <td>20</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>Apex Legends|Apex Legends characters|new Apex ...</td>\n",
       "      <td>2381688</td>\n",
       "      <td>146739</td>\n",
       "      <td>2794</td>\n",
       "      <td>16549</td>\n",
       "      <td>While running her own modding shop, Ramya Pare...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>J78aPJ3VyNs</td>\n",
       "      <td>I left youtube for a month and THIS is what ha...</td>\n",
       "      <td>2020-08-11T16:34:06Z</td>\n",
       "      <td>jacksepticeye</td>\n",
       "      <td>24</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>jacksepticeye|funny|funny meme|memes|jacksepti...</td>\n",
       "      <td>2038853</td>\n",
       "      <td>353787</td>\n",
       "      <td>2628</td>\n",
       "      <td>40221</td>\n",
       "      <td>I left youtube for a month and this is what ha...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kXLn3HkpjaA</td>\n",
       "      <td>XXL 2020 Freshman Class Revealed - Official An...</td>\n",
       "      <td>2020-08-11T16:38:55Z</td>\n",
       "      <td>XXL</td>\n",
       "      <td>10</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>xxl freshman|xxl freshmen|2020 xxl freshman|20...</td>\n",
       "      <td>496771</td>\n",
       "      <td>23251</td>\n",
       "      <td>1856</td>\n",
       "      <td>7647</td>\n",
       "      <td>Subscribe to XXL → http://bit.ly/subscribe-xxl...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VIUo6yapDbc</td>\n",
       "      <td>Ultimate DIY Home Movie Theater for The LaBran...</td>\n",
       "      <td>2020-08-11T15:10:05Z</td>\n",
       "      <td>Mr. Kate</td>\n",
       "      <td>26</td>\n",
       "      <td>2020-08-12T00:00:00Z</td>\n",
       "      <td>The LaBrant Family|DIY|Interior Design|Makeove...</td>\n",
       "      <td>1123889</td>\n",
       "      <td>45802</td>\n",
       "      <td>964</td>\n",
       "      <td>2196</td>\n",
       "      <td>Transforming The LaBrant Family's empty white ...</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      video_id                                              title  \\\n",
       "0  3C66w5Z0ixs                 I ASKED HER TO BE MY GIRLFRIEND...   \n",
       "1  M9Pmf9AB4Mo  Apex Legends | Stories from the Outlands – “Th...   \n",
       "2  J78aPJ3VyNs  I left youtube for a month and THIS is what ha...   \n",
       "3  kXLn3HkpjaA  XXL 2020 Freshman Class Revealed - Official An...   \n",
       "4  VIUo6yapDbc  Ultimate DIY Home Movie Theater for The LaBran...   \n",
       "\n",
       "            publishedAt   channelTitle  categoryId         trending_date  \\\n",
       "0  2020-08-11T19:20:14Z       Brawadis          22  2020-08-12T00:00:00Z   \n",
       "1  2020-08-11T17:00:10Z   Apex Legends          20  2020-08-12T00:00:00Z   \n",
       "2  2020-08-11T16:34:06Z  jacksepticeye          24  2020-08-12T00:00:00Z   \n",
       "3  2020-08-11T16:38:55Z            XXL          10  2020-08-12T00:00:00Z   \n",
       "4  2020-08-11T15:10:05Z       Mr. Kate          26  2020-08-12T00:00:00Z   \n",
       "\n",
       "                                                tags  view_count   likes  \\\n",
       "0  brawadis|prank|basketball|skits|ghost|funny vi...     1514614  156908   \n",
       "1  Apex Legends|Apex Legends characters|new Apex ...     2381688  146739   \n",
       "2  jacksepticeye|funny|funny meme|memes|jacksepti...     2038853  353787   \n",
       "3  xxl freshman|xxl freshmen|2020 xxl freshman|20...      496771   23251   \n",
       "4  The LaBrant Family|DIY|Interior Design|Makeove...     1123889   45802   \n",
       "\n",
       "   dislikes  comment_count                                        description  \\\n",
       "0      5855          35313  SUBSCRIBE to BRAWADIS ▶ http://bit.ly/Subscrib...   \n",
       "1      2794          16549  While running her own modding shop, Ramya Pare...   \n",
       "2      2628          40221  I left youtube for a month and this is what ha...   \n",
       "3      1856           7647  Subscribe to XXL → http://bit.ly/subscribe-xxl...   \n",
       "4       964           2196  Transforming The LaBrant Family's empty white ...   \n",
       "\n",
       "  country  \n",
       "0      US  \n",
       "1      US  \n",
       "2      US  \n",
       "3      US  \n",
       "4      US  "
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary rows \n",
    "df.drop(['channelId', 'thumbnail_link', 'comments_disabled', 'ratings_disabled'], inplace=True, axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowercase title and tags columns \n",
    "df['title'] = df['title'].str.lower()\n",
    "df['tags'] = df['tags'].str.lower()\n",
    "df['description'] = df['description'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting tag and title contents for easier parsing\n",
    "df['title content'] = df['title'].str.split()\n",
    "df['tag content'] = df['tags'].str.split(\"|\")\n",
    "df['description content'] = df['description'].str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total word count of video title (title length)\n",
    "df['total count title'] = df['title'].str.split().str.len()\n",
    "\n",
    "# Getting the total tag count of video tags (tag length)\n",
    "df['total count tag'] = df['tags'].str.split(\"|\").str.len()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Divide into 3 countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us = df[df['country'] == 'US']\n",
    "df_gb = df[df['country'] == 'GB']\n",
    "df_ca = df[df['country'] == 'CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### convert categoriesID to name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_us['categoryId'] = df_us['categoryId'].replace([24,10,20,17,22,23,28,26,25,1,27,2,19,15,29],\n",
    "                                               [\"Entertainment\",\"Music\",\"Gaming\",\"Sports\",\"People & Blogs\",\"Comedy\",\"Science & Technology\",\n",
    "                                               \"Howto & Style\",\"News & Politics\",\"Film & Animation\",\"Education\",\"Autos & Vehicles\",\"Travel & Events\",\n",
    "                                               \"Pets & Animals\",\"Nonprofits & Activism\"])\n",
    "df_ca['categoryId'] = df_ca['categoryId'].replace([24,10,20,17,22,23,28,26,25,1,27,2,19,15,29],\n",
    "                                               [\"Entertainment\",\"Music\",\"Gaming\",\"Sports\",\"People & Blogs\",\"Comedy\",\"Science & Technology\",\n",
    "                                               \"Howto & Style\",\"News & Politics\",\"Film & Animation\",\"Education\",\"Autos & Vehicles\",\"Travel & Events\",\n",
    "                                               \"Pets & Animals\",\"Nonprofits & Activism\"])\n",
    "df_gb['categoryId'] = df_gb['categoryId'].replace([24,10,20,17,22,23,28,26,25,1,27,2,19,15,29],\n",
    "                                               [\"Entertainment\",\"Music\",\"Gaming\",\"Sports\",\"People & Blogs\",\"Comedy\",\"Science & Technology\",\n",
    "                                               \"Howto & Style\",\"News & Politics\",\"Film & Animation\",\"Education\",\"Autos & Vehicles\",\"Travel & Events\",\n",
    "                                               \"Pets & Animals\",\"Nonprofits & Activism\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i.Do title, tags and description word count affect viewership count ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### title  and tag count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the total word count of video title (title length)\n",
    "df['total count title'] = df['title'].str.split().str.len()\n",
    "\n",
    "# Getting the total tag count of video tags (tag length)\n",
    "df['total count tag'] = df['tags'].str.split(\"|\").str.len()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### tag word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Create total frequency count of individual tags \n",
    "df_us['tag content'].to_list()\n",
    "us_tag_counts = dict(Counter(itertools.chain.from_iterable(df_us['tag content'].to_list())))\n",
    "\n",
    "df_gb['tag content'].to_list()\n",
    "gb_tag_counts = dict(Counter(itertools.chain.from_iterable(df_gb['tag content'].to_list())))\n",
    "\n",
    "df_ca['tag content'].to_list()\n",
    "ca_tag_counts = dict(Counter(itertools.chain.from_iterable(df_ca['tag content'].to_list())))\n",
    "\n",
    "#Convert to dataframe and sort\n",
    "us_tags = pd.DataFrame(list(us_tag_counts.items()),columns = ['tag','count']) \n",
    "us_tags = us_tags.sort_values(by='count', ascending=False)\n",
    "\n",
    "gb_tags = pd.DataFrame(list(gb_tag_counts.items()),columns = ['tag','count']) \n",
    "gb_tags = gb_tags.sort_values(by='count', ascending=False)\n",
    "\n",
    "ca_tags = pd.DataFrame(list(ca_tag_counts.items()),columns = ['tag','count']) \n",
    "ca_tags = ca_tags.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Title Count Plot Box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [df_us, df_gb, df_ca]\n",
    "\n",
    "# Merge all three dataframes\n",
    "df_merge = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pal = {\"US\": \"b\", \"GB\": \"g\", \"CA\":\"r\"}\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "plt.suptitle(\"\")\n",
    "ax.set_title(\"Title Length Across Countries\", fontdict={'fontsize':24})\n",
    "sns.boxplot(x=df_merge[\"country\"], y=df_merge[\"total count title\"], palette=my_pal)\n",
    "\n",
    "ax.set_xlabel(\"Countries\", fontdict={'fontsize':24})\n",
    "ax.set_ylabel(\"Title Length\", fontdict={'fontsize':24})\n",
    "\n",
    "plt.savefig(\"TitleCountBoxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = df_merge[df_merge[\"country\"] == 'US']\n",
    "title_usa = usa['total count title']\n",
    "\n",
    "gb = df_merge[df_merge[\"country\"] == 'GB']\n",
    "title_gb = gb['total count title']\n",
    "\n",
    "ca = df_merge[df_merge[\"country\"] == 'CA']\n",
    "title_ca = ca['total count title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quartile calculations for title length US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartile calculations for title length US\n",
    "us_quartiles = title_usa.quantile([.25,.5,.75])\n",
    "lowerq = us_quartiles[0.25]\n",
    "upperq = us_quartiles[0.75]\n",
    "iqr = upperq-lowerq\n",
    "\n",
    "print(f\"The lower quartile of US title length is: {lowerq}\")\n",
    "print(f\"The upper quartile of US title length is: {upperq}\")\n",
    "print(f\"The interquartile range of US title length is: {iqr}\")\n",
    "print(f\"The the median of US title length is: {us_quartiles[0.5]} \")\n",
    "\n",
    "lower_bound = lowerq - (1.5*iqr)\n",
    "upper_bound = upperq + (1.5*iqr)\n",
    "print(f\"Values below {lower_bound} could be outliers.\")\n",
    "print(f\"Values above {upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quartile calculations for title length GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartile calculations for title length GB\n",
    "gb_quartiles = title_gb.quantile([.25,.5,.75])\n",
    "gb_lowerq = gb_quartiles[0.25]\n",
    "gb_upperq = gb_quartiles[0.75]\n",
    "gb_iqr = gb_upperq-gb_lowerq\n",
    "\n",
    "print(f\"The lower quartile of GB title length is: {gb_lowerq}\")\n",
    "print(f\"The upper quartile of GB title length is: {gb_upperq}\")\n",
    "print(f\"The interquartile range of GB title length is: {gb_iqr}\")\n",
    "print(f\"The the median of GB title length is: {gb_quartiles[0.5]} \")\n",
    "\n",
    "gb_lower_bound = gb_lowerq - (1.5*gb_iqr)\n",
    "gb_upper_bound = gb_upperq + (1.5*gb_iqr)\n",
    "print(f\"Values below {gb_lower_bound} could be outliers.\")\n",
    "print(f\"Values above {gb_upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Quartile calculations for title length CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Quartile calculations for title length CA\n",
    "ca_quartiles = title_ca.quantile([.25,.5,.75])\n",
    "ca_lowerq = ca_quartiles[0.25]\n",
    "ca_upperq = ca_quartiles[0.75]\n",
    "ca_iqr = ca_upperq-ca_lowerq\n",
    "\n",
    "print(f\"The lower quartile of CA title length is: {ca_lowerq}\")\n",
    "print(f\"The upper quartile of CA title length is: {ca_upperq}\")\n",
    "print(f\"The interquartile range of CA title length is: {ca_iqr}\")\n",
    "print(f\"The the median of CA title length is: {ca_quartiles[0.5]} \")\n",
    "\n",
    "ca_lower_bound = ca_lowerq - (1.5*ca_iqr)\n",
    "ca_upper_bound = ca_upperq + (1.5*ca_iqr)\n",
    "print(f\"Values below {ca_lower_bound} could be outliers.\")\n",
    "print(f\"Values above {ca_upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tag Count Boxplots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot of tag count\n",
    "my_pal = {\"US\": \"b\", \"GB\": \"g\", \"CA\":\"r\"}\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15,10))\n",
    "plt.suptitle(\"\")\n",
    "ax.set_title(\"Tag Count Across Countries\", fontdict={'fontsize':24})\n",
    "sns.boxplot(x=df_merge[\"country\"], y=df_merge[\"total count tag\"], palette=my_pal)\n",
    "\n",
    "ax.set_xlabel(\"Countries\", fontdict={'fontsize':24})\n",
    "ax.set_ylabel(\"Tag Count\", fontdict={'fontsize':24})\n",
    "\n",
    "plt.savefig(\"TagCountBoxplot.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa = df_merge[df_merge[\"country\"] == 'US']\n",
    "tag_usa = usa['total count tag']\n",
    "\n",
    "gb = df_merge[df_merge[\"country\"] == 'GB']\n",
    "tag_gb = gb['total count tag']\n",
    "\n",
    "ca = df_merge[df_merge[\"country\"] == 'CA']\n",
    "tag_ca = ca['total count tag']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quartile calculations for title length US"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartile calculations for title length US\n",
    "us_tag_quartiles = tag_usa.quantile([.25,.5,.75])\n",
    "us_tag_lowerq = us_tag_quartiles[0.25]\n",
    "us_tag_upperq = us_tag_quartiles[0.75]\n",
    "us_tag_iqr = us_tag_upperq-us_tag_lowerq\n",
    "\n",
    "print(f\"The lower quartile of US title length is: {us_tag_lowerq}\")\n",
    "print(f\"The upper quartile of US title length is: {us_tag_upperq}\")\n",
    "print(f\"The interquartile range of US title length is: {us_tag_iqr}\")\n",
    "print(f\"The the median of US title length is: {us_tag_quartiles[0.5]} \")\n",
    "\n",
    "us_tag_lower_bound = us_tag_lowerq - (1.5*us_tag_iqr)\n",
    "us_tag_upper_bound = us_tag_upperq + (1.5*us_tag_iqr)\n",
    "print(f\"Values below {us_tag_lower_bound} could be outliers.\")\n",
    "print(f\"Values above {us_tag_upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quartile calculations for title length GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartile calculations for title length GB\n",
    "gb_tag_quartiles = tag_gb.quantile([.25,.5,.75])\n",
    "gb_tag_lowerq = gb_tag_quartiles[0.25]\n",
    "gb_tag_upperq = gb_tag_quartiles[0.75]\n",
    "gb_tag_iqr = gb_tag_upperq-gb_tag_lowerq\n",
    "\n",
    "print(f\"The lower quartile of US title length is: {gb_tag_lowerq}\")\n",
    "print(f\"The upper quartile of US title length is: {gb_tag_upperq}\")\n",
    "print(f\"The interquartile range of US title length is: {gb_tag_iqr}\")\n",
    "print(f\"The the median of US title length is: {gb_tag_quartiles[0.5]} \")\n",
    "\n",
    "gb_tag_lower_bound = gb_tag_lowerq - (1.5*gb_tag_iqr)\n",
    "gb_tag_upper_bound = gb_tag_upperq + (1.5*gb_tag_iqr)\n",
    "print(f\"Values below {gb_tag_lower_bound} could be outliers.\")\n",
    "print(f\"Values above {gb_tag_upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quartile calculations for title length CA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quartile calculations for title length CA\n",
    "ca_quartiles = title_ca.quantile([.25,.5,.75])\n",
    "ca_lowerq = ca_quartiles[0.25]\n",
    "ca_upperq = ca_quartiles[0.75]\n",
    "ca_iqr = ca_upperq-ca_lowerq\n",
    "\n",
    "print(f\"The lower quartile of CA title length is: {ca_lowerq}\")\n",
    "print(f\"The upper quartile of CA title length is: {ca_upperq}\")\n",
    "print(f\"The interquartile range of CA title length is: {ca_iqr}\")\n",
    "print(f\"The the median of CA title length is: {ca_quartiles[0.5]} \")\n",
    "\n",
    "ca_lower_bound = ca_lowerq - (1.5*ca_iqr)\n",
    "ca_upper_bound = ca_upperq + (1.5*ca_iqr)\n",
    "print(f\"Values below {ca_lower_bound} could be outliers.\")\n",
    "print(f\"Values above {ca_upper_bound} could be outliers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## ii Do title, tags content by categories affect viewership count?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Categories Count Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with categoryId counts\n",
    "category_counts_us = df_us['categoryId'].value_counts().to_dict()\n",
    "category_counts_gb = df_gb['categoryId'].value_counts().to_dict()\n",
    "category_counts_ca = df_ca['categoryId'].value_counts().to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_cat = pd.DataFrame(list(category_counts_ca.items()),columns = ['category','count']) \n",
    "df_gb_cat = pd.DataFrame(list(category_counts_gb.items()),columns = ['category','count'])  \n",
    "df_us_cat = pd.DataFrame(list(category_counts_us.items()),columns = ['category','count']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sorter\n",
    "sorter = ['Music', 'Entertainment', 'Gaming', 'Sports', 'People & Blogs', 'Comedy', 'Science & Technology', 'News & Politics',\n",
    "          'Howto & Style','Film & Animation','Education', 'Autos & Vehicles', 'Pets & Animals', \n",
    "          'Travel & Events', 'Nonprofits & Activism']\n",
    "\n",
    "# Create the dictionary that defines the order for sorting\n",
    "sorterIndex = dict(zip(sorter, range(len(sorter))))\n",
    "\n",
    "# Generate a rank column that will be used to sort\n",
    "# the dataframe numerically\n",
    "df_ca_cat['Tm_Rank'] = df_ca_cat['category'].map(sorterIndex)\n",
    "df_us_cat['Tm_Rank'] = df_us_cat['category'].map(sorterIndex)\n",
    "df_gb_cat['Tm_Rank'] = df_gb_cat['category'].map(sorterIndex)\n",
    "\n",
    "# Here is the result asked with the lexicographic sort\n",
    "# Result may be hard to analyze, so a second sorting is\n",
    "# proposed next\n",
    "## NOTE: \n",
    "## Newer versions of pandas use 'sort_values' instead of 'sort'\n",
    "df_ca_cat.sort_values(['Tm_Rank'], ascending=True, inplace = True)\n",
    "df_ca_cat.drop('Tm_Rank', 1, inplace = True)\n",
    "\n",
    "df_us_cat.sort_values(['Tm_Rank'], ascending=True,inplace = True)\n",
    "df_us_cat.drop('Tm_Rank', 1, inplace = True)\n",
    "\n",
    "df_gb_cat.sort_values(['Tm_Rank'], ascending=True,inplace = True)\n",
    "df_gb_cat.drop('Tm_Rank', 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ticks = []\n",
    "\n",
    "x_axis4 = df_us_cat['category']\n",
    "y_axis4 = df_us_cat['count']\n",
    "\n",
    "x_axis5 = df_gb_cat['category']\n",
    "y_axis5 = df_gb_cat['count']\n",
    "\n",
    "x_axis6 = df_ca_cat['category']\n",
    "y_axis6 = df_ca_cat['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create data\n",
    "\n",
    "ind = np.arange(15) \n",
    "width = 0.25\n",
    "\n",
    " \n",
    "# Make the plot\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.barh(ind, y_axis4, color='blue', height=width)\n",
    "plt.barh(ind+width, y_axis5, color='green', height=width)\n",
    "plt.barh(ind+width*2, y_axis6, color='red', height=width)\n",
    "plt.gca().invert_yaxis()\n",
    "\n",
    "plt.xlabel(\"Upload Count\")\n",
    "plt.ylabel(\"Category\")\n",
    "plt.title(\"Popular Categories Across Countries\")\n",
    "plt.yticks(np.arange(15),['Music', 'Entertainment', 'Gaming', 'Sports', 'People & Blogs', 'Comedy', 'Science & Technology', 'News & Politics',\n",
    "          'Howto & Style','Film & Animation','Education', 'Autos & Vehicles', 'Pets & Animals', \n",
    "          'Travel & Events', 'Nonprofits & Activism'])\n",
    "\n",
    "plt.legend(handles=[us_avg, gb_avg, ca_avg], loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "\n",
    "us_avg, = plt.plot(x_axis4, y_axis4, color=\"blue\", label=\"United States\" )\n",
    "gb_avg, = plt.plot(x_axis4, y_axis5, color=\"green\", label=\"Great Britain\" )\n",
    "ca_avg, = plt.plot(x_axis4, y_axis6, color=\"red\", label=\"Canada\" )\n",
    "\n",
    "\n",
    "\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Upload Count\")\n",
    "plt.title(\"Popular Categories Across Countries\")\n",
    "\n",
    "plt.legend(handles=[us_avg, gb_avg, ca_avg], loc=\"best\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) What are the top N hot topics for each category of videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top categories for each country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gb category video count vs top views : 10: music, 24:Entertainment, 20: gaming\n",
    "df_us_topcategory = pd.DataFrame(df_us.groupby('categoryId')['view_count'].sum()).sort_values(by = 'view_count',ascending=False).reset_index()\n",
    "video_count = pd.DataFrame(df_us['categoryId'].value_counts()).reset_index().rename(columns={'index' : 'categoryId',\n",
    "                                                                                             'categoryId':'video_count'})\n",
    "df_us_topcategory = df_us_topcategory.merge(video_count, how = 'inner', on = 'categoryId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create total frequency count of individual words in title \n",
    "us_title_list = df_us['title content'].to_list()\n",
    "us_all_title_counts = dict(Counter(itertools.chain.from_iterable(df_us['title content'].to_list())))\n",
    "\n",
    "gb_title_list = df_gb['title content'].to_list()\n",
    "gb_all_title_counts = dict(Counter(itertools.chain.from_iterable(df_gb['title content'].to_list())))\n",
    "\n",
    "ca_title_list = df_ca['title content'].to_list()\n",
    "ca_all_title_counts = dict(Counter(itertools.chain.from_iterable(df_ca['title content'].to_list())))\n",
    "\n",
    "#Convert to dataframe and sort\n",
    "df_title_us = pd.DataFrame(list(us_all_title_counts.items()),columns = ['word','count']) \n",
    "df_title_us.sort_values(by='count', ascending=False)\n",
    "\n",
    "df_title_gb = pd.DataFrame(list(gb_all_title_counts.items()),columns = ['word','count']) \n",
    "df_title_gb.sort_values(by='count', ascending=False)\n",
    "\n",
    "df_title_ca = pd.DataFrame(list(ca_all_title_counts.items()),columns = ['word','count']) \n",
    "df_title_ca.sort_values(by='count', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting hot topics with NLTK\n",
    "####  (https://www.analyticsvidhya.com/blog/2019/08/how-to-remove-stopwords-text-normalization-nltk-spacy-gensim-python/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### split categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split categories\n",
    "df_us_10 = df_us[df_us['categoryId'] == 10]\n",
    "df_us_24 = df_us[df_us['categoryId'] == 24]\n",
    "df_us_20 =  df_us[df_us['categoryId'] == 20]\n",
    "df_us_25 =  df_us[df_us['categoryId'] == 25]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Textual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extracting hot topics with NLTK\n",
    "text = df_us_10['title'].str.lower().replace('|', ' ').str.cat(sep=' ')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "word_tokens = word_tokenize(text) \n",
    "    \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "        \n",
    "# Stemming with NLTK\n",
    "Stem_words = []\n",
    "ps =PorterStemmer()\n",
    "for w in filtered_sentence:\n",
    "    rootWord=ps.stem(w)\n",
    "    Stem_words.append(rootWord)\n",
    "    \n",
    "# Lemmatization with NLTK\n",
    "filtered_sentence = list(filter(lambda token: token not in string.punctuation, filtered_sentence))\n",
    "filtered_sentence\n",
    "\n",
    "# remove unnecessay words\n",
    "stopwords = [\"'s\", \"’\", \"...\" , \"ft.\" , \"2\" ,\"x\" , \"1\", \"n't\", \"–\", \"3\", \"5\", \"4\",\n",
    "             \"2021\",\"2020\",\"trailer\", \"de\", \"official\", \"season\", \"video\", \"official\", \"season\", \"episode\",\"la\", \"le\", \"je\",\n",
    "             \"part\", \"je\", \"des\",\"world\",\"day\", \"10\",\"e\", \"avec\", \"‘\", \"à\", \"music\", \"none\", \"new\",\"lil\", \"like\", \"songs\", \"song\",\n",
    "            \"thee\",\"love\",\"bad\",\"g\",\"tv\", \"voice\",\"game\", \"news\",\"live\",\"watch\", \"full\", \"today\", \"uk\" ]\n",
    "for word in list(filtered_sentence):  # iterating on a copy since removing will mess things up\n",
    "    if word in stopwords:\n",
    "        filtered_sentence.remove(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word Cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#wordcloud\n",
    "word_could_dict= Counter(filtered_sentence)\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 500, background_color ='black',\n",
    "                      stopwords = stopwords,\n",
    "                      min_font_size = 10).generate_from_frequencies(word_could_dict)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n",
    "# plt.savefig('us20_tags_wordcloud.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hot Topic words count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_sentence = pd.DataFrame(filtered_sentence)\n",
    "filtered_sentence_unique = pd.DataFrame(filtered_sentence.value_counts())\n",
    "filtered_sentence_unique = filtered_sentence_unique.rename(columns={'0':'count'})\n",
    "filtered_sentence_unique.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to string\n",
    "# using list comprehension\n",
    "listToStr = ' '.join([str(elem) for elem in filtered_sentence_unique])\n",
    "  \n",
    "listToStr "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Does published time affect viewership count?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Published Times Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Published Times Analysis \n",
    "\n",
    "# Remove the dates, mins, and seconds in 'publshedAt' column \n",
    "df_us['publishedAt'] = df_us['publishedAt'].str[10:]\n",
    "df_us['publishedAt'] = df_us['publishedAt'].str[:3]\n",
    "\n",
    "df_gb['publishedAt'] = df_gb['publishedAt'].str[10:]\n",
    "df_gb['publishedAt'] = df_gb['publishedAt'].str[:3]\n",
    "\n",
    "df_ca['publishedAt'] = df_ca['publishedAt'].str[10:]\n",
    "df_ca['publishedAt'] = df_ca['publishedAt'].str[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe with published time counts\n",
    "time_counts_us = df_us['publishedAt'].value_counts().to_dict()\n",
    "time_counts_gb = df_gb['publishedAt'].value_counts().to_dict()\n",
    "time_counts_ca = df_ca['publishedAt'].value_counts().to_dict()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Published Time Line plot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ca_time = pd.DataFrame(list(time_counts_ca.items()),columns = ['time','count']).sort_values(by=['time']) \n",
    "df_gb_time = pd.DataFrame(list(time_counts_gb.items()),columns = ['time','count']).sort_values(by=['time'])  \n",
    "df_us_time = pd.DataFrame(list(time_counts_us.items()),columns = ['time','count']).sort_values(by=['time']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_ticks = []\n",
    "\n",
    "x_axis = df_us_time['time']\n",
    "y_axis = df_us_time['count']\n",
    "\n",
    "x_axis2 = df_ca_time['time']\n",
    "y_axis2 = df_ca_time['count']\n",
    "\n",
    "x_axis3 = df_gb_time['time']\n",
    "y_axis3 = df_gb_time['count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "us_avg, = plt.plot(x_axis, y_axis, color=\"blue\", label=\"United States\" )\n",
    "gb_avg, = plt.plot(x_axis3, y_axis3, color=\"green\", label=\"Great Britain\" )\n",
    "ca_avg, = plt.plot(x_axis2, y_axis2, color=\"red\", label=\"Canada\" )\n",
    "\n",
    "plt.xlabel(\"Published Time\")\n",
    "plt.ylabel(\"Upload Count\")\n",
    "plt.title(\"Published Times Across Countries\")\n",
    "plt.xticks([0, 2, 4,6,8,10,12,14,16,18,20,22], \n",
    "           ['12AM', '2AM','4AM','6AM','8AM','10AM','12PM','2PM','4PM','6PM','8PM', '10PM'])\n",
    "\n",
    "\n",
    "plt.legend(handles=[us_avg, gb_avg, ca_avg], loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
