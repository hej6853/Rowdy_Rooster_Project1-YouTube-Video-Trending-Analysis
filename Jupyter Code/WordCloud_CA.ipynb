{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies and Setup\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "import itertools\n",
    "import nltk\n",
    "import chardet\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from collections import Counter\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import file\n",
    "df = pd.read_csv('us_gb_ca_merged.csv') \n",
    "\n",
    "#split df into 3 countireis\n",
    "df_us = df[df['country'] == 'US']\n",
    "df_gb = df[df['country'] == 'GB']\n",
    "df_ca = df[df['country'] == 'CA']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top Video Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_gb category video count vs top views : 10: music, 24:Entertainment, 20: gaming\n",
    "df_ca_topcategory = pd.DataFrame(df_ca.groupby('categoryId')['view_count'].sum()).sort_values(by = 'view_count',ascending=False).reset_index()\n",
    "video_count = pd.DataFrame(df_ca['categoryId'].value_counts()).reset_index().rename(columns={'index' : 'categoryId',\n",
    "                                                                                             'categoryId':'video_count'})\n",
    "df_ca_topcategory = df_ca_topcategory.merge(video_count, how = 'inner', on = 'categoryId')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split categories\n",
    "df_ca_10 = df_ca[df_ca['categoryId'] == 10]\n",
    "df_ca_24 = df_ca[df_ca['categoryId'] == 24]\n",
    "df_ca_20 =  df_ca[df_ca['categoryId'] == 20]\n",
    "df_ca_25 =  df_ca[df_ca['categoryId'] == 25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Extracting hot topics with NLTK\n",
    "text = df_ca_25['tags'].str.lower().replace('|', ' ').str.cat(sep=' ')\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english')) \n",
    "  \n",
    "word_tokens = word_tokenize(text) \n",
    "    \n",
    "filtered_sentence = [] \n",
    "  \n",
    "for w in word_tokens: \n",
    "    if w not in stop_words: \n",
    "        filtered_sentence.append(w) \n",
    "        \n",
    "# Stemming with NLTK\n",
    "Stem_words = []\n",
    "ps =PorterStemmer()\n",
    "for w in filtered_sentence:\n",
    "    rootWord=ps.stem(w)\n",
    "    Stem_words.append(rootWord)\n",
    "    \n",
    "# Lemmatization with NLTK\n",
    "filtered_sentence = list(filter(lambda token: token not in string.punctuation, filtered_sentence))\n",
    "filtered_sentence\n",
    "\n",
    "# remove unnecessay words\n",
    "stopwords = [\"'s\", \"’\", \"...\" , \"ft.\" , \"2\" ,\"x\" , \"1\", \"n't\", \"–\", \"3\", \"5\", \"4\",\n",
    "             \"2021\",\"2020\",\"trailer\", \"de\", \"official\", \"season\", \"video\", \"official\", \"season\", \"episode\",\"la\", \"le\", \"je\",\n",
    "             \"part\", \"je\", \"des\",\"world\",\"day\", \"10\",\"e\", \"avec\", \"‘\", \"à\", \"music\", \"none\", \"new\",\"lil\", \"like\", \"songs\", \"song\",\n",
    "            \"thee\",\"love\",\"bad\",\"g\",\"tv\", \"voice\",\"game\", \"news\",\"update\", \"man\",\"april\",\"watch\",\"today\",\"live\", \"first\",\"us\",\n",
    "             \"worth\",\"latest\",\"14\", \"show\"            ]\n",
    "for word in list(filtered_sentence):  # iterating on a copy since removing will mess things up\n",
    "    if word in stopwords:\n",
    "        filtered_sentence.remove(word)\n",
    "        \n",
    "#wordcloud\n",
    "word_could_dict=Counter(filtered_sentence)\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 500, background_color ='black',  stopwords = stopwords,\n",
    "                min_font_size = 10).generate_from_frequencies(word_could_dict)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(15,8))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "# plt.show()\n",
    "plt.savefig('ca25_tags_wordcloud.png', bbox_inches='tight')\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>philip</th>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>election</th>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prince</th>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harry</th>\n",
       "      <td>104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eugenie</th>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news|us</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biden</th>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>william</th>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>british</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news|coronavirus</th>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news|finance</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news|world</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>vincent</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>boseman</th>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump</th>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alberta|government</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>election|2020</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meghan</th>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uk</th>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>earthquake</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>protest</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hill</th>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>president</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>update|coronavirus</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>national</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>harris</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parts</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>debris</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>city</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elizabeth</th>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>house</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>louis</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hinshaw</th>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trump|trump</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markle</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fire</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market|news</th>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edinburgh</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>donald</th>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bbc|bbc</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>presidential</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>station|breaking</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>joe</th>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>morning</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capitol</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>news|cable|cable</th>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>floyd</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bader</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      0\n",
       "0                      \n",
       "philip              200\n",
       "election            194\n",
       "prince              110\n",
       "harry               104\n",
       "eugenie              98\n",
       "covid                95\n",
       "news|us              93\n",
       "biden                91\n",
       "william              83\n",
       "british              78\n",
       "news|coronavirus     74\n",
       "news|finance         67\n",
       "news|world           65\n",
       "vincent              64\n",
       "boseman              63\n",
       "trump                62\n",
       "alberta|government   60\n",
       "election|2020        59\n",
       "meghan               59\n",
       "uk                   58\n",
       "earthquake           56\n",
       "protest              56\n",
       "hill                 56\n",
       "president            55\n",
       "update|coronavirus   55\n",
       "national             54\n",
       "harris               53\n",
       "power                51\n",
       "parts                50\n",
       "debris               50\n",
       "city                 49\n",
       "elizabeth            49\n",
       "house                48\n",
       "louis                48\n",
       "hinshaw              48\n",
       "trump|trump          47\n",
       "markle               47\n",
       "fire                 46\n",
       "market|news          46\n",
       "edinburgh            45\n",
       "donald               45\n",
       "bbc|bbc              44\n",
       "presidential         44\n",
       "station|breaking     43\n",
       "joe                  42\n",
       "morning              41\n",
       "capitol              41\n",
       "news|cable|cable     41\n",
       "floyd                40\n",
       "bader                40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sentence = pd.DataFrame(filtered_sentence)\n",
    "filtered_sentence_unique = pd.DataFrame(filtered_sentence.value_counts())\n",
    "filtered_sentence_unique = filtered_sentence_unique.rename(columns={'0':'count'})\n",
    "filtered_sentence_unique.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
